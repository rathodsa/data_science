{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7396df2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (1726867639.py, line 204)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''Write the observations''\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Data aquisition\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-2/master/CaseStudy/Advertising.csv', index_col=0) \n",
    "print('Data Shape:', data.shape)\n",
    "data.head()\n",
    "\n",
    "#Data description and pre-processing\n",
    "data.describe()\n",
    "\n",
    "import pandas_profiling as pp\n",
    "\n",
    "profile = pp.ProfileReport(data)\n",
    "\n",
    "profile\n",
    "\n",
    "data.info()\n",
    "\n",
    "#Exploratory Data analysis\n",
    "plt.style.use(\"classic\")\n",
    "sns.jointplot('newspaper','sales', data=data)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"classic\")\n",
    "sns.jointplot('TV','sales', data=data)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"classic\")\n",
    "sns.jointplot('radio','sales', data=data)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"classic\")\n",
    "sns.jointplot('TV','sales',data=data, kind=\"reg\")\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(data,size = 2, aspect= 1.5)\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(data.corr(), annot=True)\n",
    "\n",
    "'''\n",
    "1. Better relation ship between TV and sales with 0.78\n",
    "2. Weak relationship between radio, with sales 0.58\n",
    "3. very weak relation or no relation between newspaper with sales \n",
    "4. correlation can process between +1 to -1 +1 means strong relation ship and -1 means very weak relation ship\n",
    "5. here in the data, TV and sales are correlation of 0.78 out of all independent variables hence TV and sales are most probable candidate for model building\n",
    "''' \n",
    "\n",
    "feature_cols = ['TV', 'newspaper', 'radio']\n",
    "X = data[feature_cols]\n",
    "X.head()\n",
    "\n",
    "y = data.sales\n",
    "\n",
    "y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.40,random_state=0)\n",
    "\n",
    "print('X Train share:', X_train.shape)\n",
    "print('X test shape:', X_test.shape)\n",
    "print('y train shape:', y_train.shape)\n",
    "print('y test shape:', y_test.shape)\n",
    "\n",
    "#standardisation \n",
    "# Variable that zre measured at different scales do not contribute to the model building and hence we will endup with bias\n",
    "# to deal with this scenario, we will use standardisation method before model fitting\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[feature_cols] = sc.fit_transform(X_train[feature_cols])\n",
    "X_test[feature_cols] = sc.transform(X_test[feature_cols])\n",
    "\n",
    "X_train.describe()\n",
    "\n",
    "X_test.describe()\n",
    "\n",
    "\n",
    "\n",
    "# Model Developement and Evaluation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr\n",
    "\n",
    "y = lr.coef_\n",
    "\n",
    "c = lr.intercept_\n",
    "\n",
    "y\n",
    "\n",
    "c\n",
    "\n",
    "feature_cols\n",
    "\n",
    "feature_cols.insert(0,'Intercept')\n",
    "\n",
    "feature_cols\n",
    "\n",
    "coef = lr.coef_.tolist()\n",
    "\n",
    "coef\n",
    "\n",
    "coef.insert(0, lr.intercept_)\n",
    "\n",
    "coef\n",
    "\n",
    "eq1 = zip(feature_cols, coef)\n",
    "for c1,c2 in eq1:\n",
    "    print(c1,c2)\n",
    "\n",
    "\n",
    "\n",
    "#Using the model for predictions\n",
    "y_pred_train = lr.predict(X_train)\n",
    "\n",
    "y_pred_test = lr.predict(X_test)\n",
    "\n",
    "y_pred_train\n",
    "\n",
    "y_pred_test\n",
    "\n",
    "plt.style.use(\"classic\")\n",
    "sns.regplot(y_test,y_pred_test)\n",
    "plt.show()\n",
    "\n",
    "# Model evaluation using metrics \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "print(mean_absolute_error(y_train,y_pred_train))\n",
    "print(mean_absolute_error(y_test, y_pred_test))\n",
    "\n",
    "MSE_train = mean_squared_error(y_train, y_pred_train)\n",
    "MSE_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "RMSE_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "RMSE_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(RMSE_train, RMSE_test)\n",
    "\n",
    "# Model evaluation using r squared and adjusted r squared\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(r2_train, r2_test)\n",
    "\n",
    "adj_r_squared_train = 1 - (1-r2_train)*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
    "adj_r_squared_test = 1 - (1-r2_test)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "\n",
    "print(\"Adjusted R2 score for training set is {}\".format(adj_r_squared_train))\n",
    "print(\"Adjusted R2 score for test set is {}\".format(adj_r_squared_test))\n",
    "\n",
    "'''\n",
    "Observation :\n",
    "\n",
    "1) R squared and adjusted r squared values for the training set is observed to be 0.9005511298841222 and 0.8979791763466426\n",
    "2) R squared and adjusted r squared values for the test data set is ibserved to be 0.8876696235952205 and 0.8832355297897687\n",
    "'''\n",
    "\n",
    "\n",
    "#Feature selection\n",
    "feature_cols = ['TV', 'radio']\n",
    "X = data[feature_cols]\n",
    "y = data.sales\n",
    "\n",
    "X.columns\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.40, random_state=1)\n",
    "\n",
    "X_train\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = lr2.predict(X_train)\n",
    "y_pred_test = lr2.predict(X_test)\n",
    "\n",
    "y_pred_train\n",
    "\n",
    "y_pred_test\n",
    "\n",
    "print(mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "print(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_train,y_pred_train)))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "\n",
    "r2_train = r2_score(y_train,y_pred_train)\n",
    "r2_test = r2_score(y_test,y_pred_test)\n",
    "print(\"R2 score for training is :\", r2_train)\n",
    "print(\"R2 score for test is :\", r2_test)\n",
    "\n",
    "#adjusted R2\n",
    "adj_r2_train = 1 - (1-r2_train)*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
    "adj_r2_test = 1 - (1-r2_test)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "print(\"Adjusted R2 score for training dataset is :\", adj_r2_train)\n",
    "print(\"adjusted R2 score for test dataset is :\", adj_r2_test)\n",
    "\n",
    "'''Write the observations''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2b276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
